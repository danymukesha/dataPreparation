[{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Data Processing Phase 1 Report","text":"report outlines data processing steps involved phase 1. covers various preprocessing tasks reformatting material names, adding missing phenotype data, selecting metadata, deduplication, imputation missing values, performing principal component analysis (PCA).","code":""},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"setup","dir":"Articles","previous_headings":"Introduction","what":"Setup","title":"Data Processing Phase 1 Report","text":"section, set necessary libraries configurations data processing tasks.","code":"library(dataPreparation) library(readxl) library(stringr) library(dplyr) library(data.table)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"data-loading","dir":"Articles","previous_headings":"Introduction","what":"Data Loading","title":"Data Processing Phase 1 Report","text":"start loading raw data Excel file containing normalized data. data used subsequent preprocessing steps.","code":"# Read the Excel file containing normalized data data <- read.table(\"../inst/extdata/allbatches_uM_clean.txt\",                     sep = \"\\t\", header = TRUE)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"reformatting-material-names","dir":"Articles","previous_headings":"","what":"Reformatting Material Names","title":"Data Processing Phase 1 Report","text":"ensure consistency clarity material names, perform reformatting material names. step involves mapping specific material names standardized formats.","code":"rep_str <- c(   '20 (serum)' = 'serum',   '30 (plasma)' = 'plasma',   '302 (EDTA plasma)' = 'plasma' )  data <- data %>%   mutate(Material = case_when(     Material %in% names(rep_str) ~ rep_str[Material],     TRUE ~ Material   ))"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"processing-sample-identification","dir":"Articles","previous_headings":"","what":"Processing Sample.Identification","title":"Data Processing Phase 1 Report","text":"perform reformatting Sample names. step involves mapping s pecific sample names standardized formats.","code":"data$`Sample.Identification` <-   ifelse(     substr(data$`Sample.Identification`, 1, 1) == \"F\",     substr(data$`Sample.Identification`, 1, 8),     data$`Sample.Identification`   )"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"adding-missing-phenotype-data","dir":"Articles","previous_headings":"","what":"Adding Missing Phenotype Data","title":"Data Processing Phase 1 Report","text":"Phenotype data essential downstream analysis. step, add missing phenotype data main dataset merging additional information external sources. developed function ad-hoc dataPreparation::add_missing_phenotypes","code":"# Load additional phenotype information all_samples_info <-    data.table::fread(input = \"../inst/extdata/additional_info.tsv\",                      sep = \"\\t\")  |>   as.data.frame() colnames(all_samples_info) <- gsub(pattern = \" \",                                     replacement = \".\",                                     x = colnames(all_samples_info)) head(all_samples_info) #>   Patient.reference Phenotype Gender Age Plasma-LH    Serum   Plasma-LH #> 1    ADIA03FR120087      miAD   Male  74  F1916088 F1916087 F1916088001 #> 2    ADIA03CH090047      miAD   Male  83           F1915909             #> 3    ADIA03CH090046      miAD   Male  81  F1915905 F1915904 F1915905001 #> 4    ADIA03CH090045      msAD Female  78  F1915900 F1915899 F1915900001 #> 5    ADIA03CH090044      miAD   Male  76           F1915894             #> 6    ADIA03CH090043      miAD Female  67           F1915889             #>         Serum Serum       Serum #> 1 F1916087001       F1916087012 #> 2                   F1915909012 #> 3 F1915904001       F1915904012 #> 4 F1915899001       F1915899010 #> 5                   F1915894011 #> 6                   F1915889012 # Add missing phenotype information data <- dataPreparation::add_missing_phenotypes(data, all_samples_info) data <- data |>   dplyr::relocate(Gender,                    Age,                    .before = Sample.Description)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"selecting-metadata","dir":"Articles","previous_headings":"","what":"Selecting Metadata","title":"Data Processing Phase 1 Report","text":"Metadata selection involves choosing relevant columns dataset provide information sample. metadata columns crucial sample identification downstream analysis.","code":"# Select metadata allmetadata <- data[,c(\"Sample.Identification\",                         \"Sample.Type\",                         \"Sample.Description\",                         \"Gender\",                         \"Age\",                         \"Material\")]  allmetadata <- unique(allmetadata)  # Filter metadata for samples allmetadata <- allmetadata %>%   filter(Sample.Type == \"Sample\")  # Filter data for samples data <- data %>%   filter(Sample.Type == \"Sample\")  # Remove temporary objects rm(list = setdiff(ls(), c(\"allmetadata\",                            \"data\",                            \"add_missing_phenotypes\",                            \"fncols\",                             \"all_samples_info\")))  data %>%   head() %>%   tibble::as.tibble() #> Warning: `as.tibble()` was deprecated in tibble 2.0.0. #> ℹ Please use `as_tibble()` instead. #> ℹ The signature and semantics have changed, see `?as_tibble`. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated. #> # A tibble: 6 × 416 #>   Sample.Type Sample.Identification Gender   Age Sample.Description #>   <chr>       <chr>                 <chr>  <int> <chr>              #> 1 Sample      F1800067              Female    93 DLB                #> 2 Sample      F1701006              Male      68 DLB                #> 3 Sample      F1915899              Female    78 msAD               #> 4 Sample      F1912538              Male      63 msAD               #> 5 Sample      F1815069              Male      83 miAD               #> 6 Sample      F1705317              Female    78 miAD               #> # ℹ 411 more variables: Submission.Name <chr>, Material <chr>, AC.0.0. <dbl>, #> #   AC.2.0. <dbl>, AC.3.0. <dbl>, AC.3.0.DC. <dbl>, AC.3.0.OH. <dbl>, #> #   AC.3.1. <dbl>, AC.4.0. <dbl>, AC.4.0.DC. <dbl>, AC.4.0.OH. <dbl>, #> #   AC.4.1. <dbl>, AC.4.1.DC. <dbl>, AC.5.0. <dbl>, AC.5.0.DC. <dbl>, #> #   AC.5.0.OH. <dbl>, AC.5.1. <dbl>, AC.5.1.DC. <dbl>, AC.6.0. <dbl>, #> #   AC.6.0.DC. <dbl>, AC.6.0.OH. <dbl>, AC.6.1. <dbl>, AC.7.0. <dbl>, #> #   AC.7.0.DC. <dbl>, AC.8.0. <dbl>, AC.8.1. <dbl>, AC.8.1.OH. <dbl>, …"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"writing-metadata-and-data","dir":"Articles","previous_headings":"","what":"Writing Metadata and Data","title":"Data Processing Phase 1 Report","text":"selecting metadata preparing dataset, write metadata cleaned data separate CSV files future reference analysis.","code":"# Write metadata to a CSV file write.table(allmetadata, file = \"../inst/data_to_use/all_metadata.csv\", row.names = FALSE, sep = \",\")  # Write data to a CSV file write.table(data, file = \"../inst/data_to_use/all_batches.csv\", sep = \",\", row.names = FALSE, col.names = TRUE, quote = FALSE)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"deduplication","dir":"Articles","previous_headings":"","what":"Deduplication","title":"Data Processing Phase 1 Report","text":"Deduplication necessary handle cases multiple entries sample exist. aggregate duplicated rows calculating mean numeric columns assigning common submission name.","code":"# Use the aggregate function to calculate the mean for duplicated rows # Merge the data by taking the mean of numeric columns and assigning the Submission.Name as \"Plate 1-2\" df_deduplicated <- data %>%   group_by(Sample.Identification) %>%   summarize(across(where(is.numeric), mean),             Submission.Name = if_else(n() > 1, \"Plate 1-2\", Submission.Name[1]),             Sample.Description = Sample.Description[1],             Material = Material[1],             Sample.Type = Sample.Type[1],             Gender = Gender[1]) %>%   ungroup()   df_deduplicated <- df_deduplicated %>% relocate(Sample.Type,                                                  Sample.Description,                                                  Gender,                                                  Age,                                                  Material,                                                  Submission.Name,                                                 .after = Sample.Identification)  meta_deduplicated <- unique(allmetadata)  # Merge metadata and raw_data using a common key combined_data <- df_deduplicated  # Remove temporary objects rm(list = setdiff(   ls(),   c(     \"allmetadata\",     \"data\",     \"add_missing_phenotypes\",     \"fncols\",     \"combined_data\"   ) ))"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"adding-cohort-information","dir":"Articles","previous_headings":"","what":"Adding Cohort Information","title":"Data Processing Phase 1 Report","text":"Cohort information provides context sample population. , add cohort information based sample description, distinguishing different cohorts.","code":"combined_data$Cohort <- NA combined_data[grepl(pattern = \"AD\",                      substr(                        combined_data$Sample.Description,                        start = 3,                        stop = 5                      )), ]$Cohort <- \"AD\" combined_data[!grepl(pattern = \"AD\",                       substr(                         combined_data$Sample.Description,                         start = 3,                         stop = 5                       )), ]$Cohort <- combined_data[!grepl(pattern = \"AD\",                       substr(                         combined_data$Sample.Description,                         start = 3,                         stop = 5                       )), ]$Sample.Description combined_data <- combined_data %>%   relocate(Cohort, .after = Sample.Description)  colnames(combined_data)[1] <- \"sampleID\" colnames(combined_data)[4] <- \"Allgr\""},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"writing-combined-data","dir":"Articles","previous_headings":"","what":"Writing Combined Data","title":"Data Processing Phase 1 Report","text":"deduplication cohort assignment, write combined processed data CSV file analysis.","code":"# write.csv(x = combined_data, file = \"../inst/data_to_use/CLEAN_combined_data_allbatches.csv\", row.names = FALSE)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"preprocessing-data","dir":"Articles","previous_headings":"","what":"Preprocessing Data","title":"Data Processing Phase 1 Report","text":"step, preprocess data removing columns high missingness imputing missing values using k-nearest neighbors (knn) algorithm. developed function ad-hoc dataPreparation::remove_high_missingness","code":"# Select the raw data data <- combined_data %>%   dplyr::select(-c(1:8))  # Remove rows with high missingness and impute missing values with k-nearest neighbors (knn) elaborated_data <- dataPreparation::remove_high_missingness(data) #> Columns removed due to more than 10 % missing values: #> AC.4.0. : 14.59459 % missing #> AC.4.0.DC. : 12.97297 % missing #> AC.4.1. : 14.59459 % missing #> AC.4.1.DC. : 12.97297 % missing #> AC.5.0.DC. : 12.97297 % missing #> AC.5.0.OH. : 12.97297 % missing #> AC.5.1.DC. : 12.97297 % missing #> AC.6.0. : 12.97297 % missing #> AC.6.0.DC. : 12.97297 % missing #> AC.6.1. : 12.97297 % missing #> AC.7.0. : 12.97297 % missing #> Ile : 25.40541 % missing #> xLeu : 41.08108 % missing #> PEA : 25.94595 % missing #>  #> Rows removed due to more than 10 % missing values: #> Row 153 : 79.4621 % missing #>  #> Columns removed due to having  0  variance: #> Carnosine   #> LPC.9.0.   #> PC.30.2.   #> PC.O.31.1.   #> PC.O.33.4.   #> PC.O.38.1.   #> PC.O.44.3. imputed_data <- elaborated_data$cleaned_data %>%   as.matrix() %>%   impute::impute.knn()  # Select categories categories <- combined_data %>%   dplyr::slice(-(elaborated_data$row_missing_percent)) %>%   dplyr::select(Sample.Description, Submission.Name)  # Add categories to imputed data imputed_data$categories <- categories  # Remove temporary objects rm(list = setdiff(   ls(),   c(     \"allmetadata\",     \"data\",     \"add_missing_phenotypes\",     \"fncols\",     \"combined_data\",     \"elaborated_data\",     \"imputed_data\",     \"remove_high_missingness\"   ) ))"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"writing-imputed-data","dir":"Articles","previous_headings":"","what":"Writing imputed data","title":"Data Processing Phase 1 Report","text":", save data rows high missingness removed impute missing values k-nearest neighbors (knn).","code":"write.csv(x = combined_data, file = \"../inst/data_to_use/imputed_data_allbatches.csv\", row.names = FALSE) usethis::use_data(imputed_data, overwrite = TRUE) #> ✔ Setting active project to 'C:/08_pkgs/dataPreparation' #> ✔ Saving 'imputed_data' to 'data/imputed_data.rda' #> • Document your data (see 'https://r-pkgs.org/data.html')"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_1.html","id":"performing-principal-component-analysis-pca","dir":"Articles","previous_headings":"","what":"Performing Principal Component Analysis (PCA)","title":"Data Processing Phase 1 Report","text":"Principal Component Analysis (PCA) dimensionality reduction technique helps visualize variation dataset. , perform PCA preprocessed data create PCA plot visualization.","code":"# Perform PCA pca_result <- prcomp(imputed_data$data, scale. = TRUE, center = TRUE)  # Extract PCA scores pca_scores <- as.data.frame(pca_result$x)  # Combine PCA scores with categories for visualization pca_data <- cbind(pca_scores, imputed_data$categories)  # Create PCA plot pca_plot <- ggplot2::ggplot(pca_data,                              ggplot2::aes(x = PC1, y = PC2,                                           color = Submission.Name,                                           shape = Sample.Description)) +     ggplot2::geom_point(size = 2) +     ggplot2::scale_shape_manual(values = c(16, 17, 18, 19)) +     ggplot2::theme_bw() +     ggplot2::labs(       title = \"PCA Plot\",       x = paste0(         \"PC1 (Explained Variance: \",         round(pca_result$sdev[1] ^ 2 / sum(pca_result$sdev ^ 2) * 100, 2),         \"%)\"       ),       y = paste0(         \"PC2 (Explained Variance: \",         round(pca_result$sdev[2] ^ 2 / sum(pca_result$sdev ^ 2) * 100, 2),         \"%)\"       )     )  # Display PCA plot pca_plot png(\"../man/figures/pca_plot.png\", width=1600, height=1200, res=220) print(pca_plot) dev.off()  #> agg_png  #>       2"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Data Processing Phase 2 Report","text":"report focuses data processing steps involved phase 2. encompasses filtering data, transforming using Compositional Log-Ratio (CLR) transformation, assessing batch effects, applying batch correction methods removeBatchEffect, ComBat, PLSDA-batch, sPLSDA-batch, percentile normalization.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"setup","dir":"Articles","previous_headings":"Introduction","what":"Setup","title":"Data Processing Phase 2 Report","text":"section, set necessary libraries configurations data processing tasks.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"data-loading","dir":"Articles","previous_headings":"Introduction","what":"Data Loading","title":"Data Processing Phase 2 Report","text":"","code":"categories <- dataPreparation::imputed_data$categories imputed_data <- dataPreparation::imputed_data"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"preparing-data-for-analysis","dir":"Articles","previous_headings":"","what":"Preparing Data for Analysis","title":"Data Processing Phase 2 Report","text":"begin filtering data using PreFL() function PLSDAbatch package remove features zero variance. step crucial reducing noise improving quality dataset.","code":"# Filter the data filter.res <- PLSDAbatch::PreFL(data = imputed_data$data,                                  keep.spl = 0,                                  keep.var = 0.00) filter <- filter.res$data.filter  # Calculate zero proportion before filtering filter.res$zero.prob #> [1] 0.1164276  # Calculate zero proportion after filtering sum(filter == 0) / (nrow(filter) * ncol(filter)) #> [1] 0.1164276"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"transforming-data","dir":"Articles","previous_headings":"","what":"Transforming Data","title":"Data Processing Phase 2 Report","text":"Next, transform filtered data using CLR transformation method mixOmics package. transformation essential handling compositional data preparing analysis.","code":"# Perform CLR transformation clr <- mixOmics::logratio.transfo(X = filter, logratio = 'CLR', offset = 1)  class(clr) = 'matrix'"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"assessing-batch-effects","dir":"Articles","previous_headings":"","what":"Assessing Batch Effects","title":"Data Processing Phase 2 Report","text":"applying batch correction methods, assess batch effects data using principal component analysis (PCA) variance partitioning analysis (pRDA). Understanding sources variation data crucial selecting appropriate batch correction techniques.","code":"# Perform PCA pca.before <- mixOmics::pca(clr, ncomp = 4, scale = TRUE)  batch = factor(categories$Submission.Name, levels = unique(categories$Submission.Name))  descr = as.factor(categories$Sample.Description)  names(batch) <- names(descr) <- rownames(categories)  # Perform pRDA factors.df <- data.frame(trt = descr, batch = batch) rda.before <- vegan::varpart(clr, ~ descr, ~ batch,                               data = factors.df,                               scale = TRUE) rda.before$part$indfract #>                 Df R.squared Adj.R.squared Testable #> [a] = X1|X2      3        NA   0.010742410     TRUE #> [b] = X2|X1      2        NA   0.063271790     TRUE #> [c]              0        NA   0.008237267    FALSE #> [d] = Residuals NA        NA   0.917748533    FALSE"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"batch-correction","dir":"Articles","previous_headings":"","what":"Batch Correction","title":"Data Processing Phase 2 Report","text":"apply various batch correction methods, including removeBatchEffect, ComBat, PLSDA-batch, sPLSDA-batch, mitigate batch effects data. methods adjust technical variation introduced batch processing improve accuracy downstream analysis.","code":"# Managing batch effects clr <- clr[seq_len(nrow(clr)), seq_len(ncol(clr))] lm <- PLSDAbatch::linear_regres(data = clr, trt = descr,                         batch.fix = batch, type = 'linear model')  p <- sapply(lm$lm.table, function(x){x$coefficients[2,4]}) p.adj <- p.adjust(p = p, method = 'fdr')  performance::check_model(lm$model$AC.0.0.) mod <- model.matrix( ~ descr) # Applying removeBatchEffect rBE <- t(limma::removeBatchEffect(t(clr), batch = batch,                                design = mod))  # Applying ComBat ComBat <- t(sva::ComBat(t(clr), batch = batch,                        mod = mod, par.prior = FALSE)) #> Found3batches #> Adjusting for3covariate(s) or covariate level(s) #> Standardizing Data across genes #> Fitting L/S model and finding priors #> Finding nonparametric adjustments #> Adjusting the Data  # Applying PLSDA-batch trt.tune <- mixOmics::plsda(X = clr, Y = descr, ncomp = 5) trt.tune$prop_expl_var #1 #> $X #>      comp1      comp2      comp3      comp4      comp5  #> 0.26290693 0.12924845 0.05638917 0.03215048 0.02706694  #>  #> $Y #>     comp1     comp2     comp3     comp4     comp5  #> 0.3476251 0.2891150 0.3600766 0.2659962 0.2676497 ad.batch.tune <- PLSDAbatch::PLSDA_batch(X = clr,                               Y.trt = descr, Y.bat = batch,                              ncomp.trt = 1, ncomp.bat = 10) ad.batch.tune$explained_variance.bat #4 #> $X #>      comp1      comp2      comp3      comp4      comp5      comp6      comp7  #> 0.14292479 0.10174322 0.03427346 0.06747000 0.03815020 0.04497184 0.02583589  #>      comp8      comp9     comp10  #> 0.01847801 0.02436724 0.02655150  #>  #> $Y #>        comp1        comp2        comp3        comp4        comp5        comp6  #> 5.341427e-01 4.658573e-01 5.071576e-01 4.926108e-01 2.315492e-04 4.526386e-01  #>        comp7        comp8        comp9       comp10  #> 5.473345e-01 2.691126e-05 5.364903e-01 4.634230e-01 PLSDA_batch.res <- PLSDAbatch::PLSDA_batch(X = clr,                                    Y.trt = descr, Y.bat = batch,                                   ncomp.trt = 1, ncomp.bat = 4) PLSDA_batch <- PLSDA_batch.res$X.nobatch  # Applying sPLSDA-path set.seed(777) test.keepX = c(seq(1, 10, 1), seq(20, 100, 10),                    seq(150, 231, 50), 231) trt.tune.v <- mixOmics::tune.splsda(X = clr, Y = descr,                               ncomp = 1, test.keepX = test.keepX,                               validation = 'Mfold', folds = 4,                               nrepeat = 50) trt.tune.v$choice.keepX #> comp1  #>    10 batch.tune <- PLSDAbatch::PLSDA_batch(X = clr,                               Y.trt = descr, Y.bat = batch,                              ncomp.trt = 1, keepX.trt = 100,                              ncomp.bat = 10) batch.tune$explained_variance.bat #4 #> $X #>      comp1      comp2      comp3      comp4      comp5      comp6      comp7  #> 0.14466418 0.19348074 0.04564147 0.04479356 0.03973901 0.03189720 0.02852764  #>      comp8      comp9     comp10  #> 0.01831160 0.01896804 0.01809190  #>  #> $Y #>        comp1        comp2        comp3        comp4        comp5        comp6  #> 0.5479060947 0.4520939053 0.4378574162 0.5601067216 0.0020358622 0.4492919487  #>        comp7        comp8        comp9       comp10  #> 0.5503150076 0.0003930436 0.4854369810 0.2951775425 sum(batch.tune$explained_variance.bat$Y[seq_len(4)]) #> [1] 1.997964 sPLSDA_batch.res <- PLSDAbatch::PLSDA_batch(X = clr,                                     Y.trt = descr, Y.bat = batch,                                    ncomp.trt = 1, keepX.trt = 100,                                    ncomp.bat = 4) sPLSDA_batch <- sPLSDA_batch.res$X.nobatch  # Applying PN PN <- PLSDAbatch::percentile_norm(data = clr, batch = batch,                           trt = descr, ctrl.grp = '0-0.5')"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"evaluating-batch-correction","dir":"Articles","previous_headings":"","what":"Evaluating Batch Correction","title":"Data Processing Phase 2 Report","text":"evaluate effectiveness batch correction methods, compare variance explained treatment batch factors correction. also assess impact correction distribution samples using scatter plots density plots.","code":"# Perform PCA after batch correction pca.rBE <- mixOmics::pca(rBE, ncomp = 3, scale = TRUE) pca.ComBat <- mixOmics::pca(ComBat, ncomp = 3, scale = TRUE) pca.PLSDA_batch <- mixOmics::pca(PLSDA_batch, ncomp = 3, scale = TRUE) pca.sPLSDA_batch <- mixOmics::pca(sPLSDA_batch, ncomp = 3, scale = TRUE)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"selecting-features","dir":"Articles","previous_headings":"","what":"Selecting Features","title":"Data Processing Phase 2 Report","text":"Finally, select features relevant discrimination treatment groups using sparse partial least squares discriminant analysis (sPLSDA). step helps identify biomarkers features contribute significantly group separation biological interpretation.","code":"# order batches batch <- factor(categories$Submission.Name,                 levels = unique(categories$Submission.Name))  pca.before.plot <- PLSDAbatch::Scatter_Density(object = pca.before,                                        batch = batch,                                        trt = descr,                                        title = 'Before correction') pca.rBE.plot <- PLSDAbatch::Scatter_Density(object = pca.rBE,                                     batch = batch,                                     trt = descr,                                     title = 'removeBatchEffect') pca.ComBat.plot <- PLSDAbatch::Scatter_Density(object = pca.ComBat,                                        batch = batch,                                        trt = descr,                                        title = 'ComBat') pca.PLSDA_batch.plot <- PLSDAbatch::Scatter_Density(object = pca.PLSDA_batch,                                             batch = batch,                                             trt = descr,                                             title = 'PLSDA-batch') pca.sPLSDA_batch.plot <- PLSDAbatch::Scatter_Density(object = pca.sPLSDA_batch,                                              batch = batch,                                              trt = descr,                                              title = 'sPLSDA-batch') g <- ggpubr::ggarrange(pca.before.plot,            pca.rBE.plot,           pca.ComBat.plot,           pca.PLSDA_batch.plot,           pca.sPLSDA_batch.plot,           labels = c(\"A\", \"B\", \"C\", \"D\", \"E\"),           ncol = 2, nrow = 3) corrected.list <- list(`Before correction` = clr,                            removeBatchEffect = rBE,                            ComBat = ComBat,                           `PLSDA-batch` = PLSDA_batch,                           `sPLSDA-batch` = sPLSDA_batch                           # `Percentile Normalisation` = PN,                           # RUVIII = RUVIII                           ) factors.df <- data.frame(trt = descr, batch = batch)  prop.df <- data.frame(\"Disease Pheno\" = NA, Batch = NA,                           Intersection = NA,                           Residuals = NA)  for(i in seq_len(length(corrected.list))){   rda.res = vegan::varpart(corrected.list[[i]], ~ descr, ~ batch,                     data = factors.df, scale = TRUE)   prop.df[i, ] <- rda.res$part$indfract$Adj.R.squared}  rownames(prop.df) = names(corrected.list)  prop.df <- prop.df[, c(1,3,2,4)]  prop.df[prop.df < 0] = 0 prop.df <- as.data.frame(t(apply(prop.df, 1,                                      function(x){x/sum(x)})))  PLSDAbatch::partVar_plot(prop.df = prop.df)"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"other-methods","dir":"Articles","previous_headings":"Selecting Features","what":"other methods","title":"Data Processing Phase 2 Report","text":"","code":"d <-   dataPreparation::visualize_batch_correction(     corrected_list = corrected.list,     categories = categories,     visualization_type = \"barplot\"   ) d splsda.select <- list() for(i in seq_len(length(corrected.list))){   splsda.res <- mixOmics::splsda(X = corrected.list[[i]], Y = descr,                         ncomp = 3, keepX = rep(50,3))   select.res <- mixOmics::selectVar(splsda.res, comp = 1)$name   splsda.select[[i]] <- select.res } names(splsda.select) <- names(corrected.list)  # can only visualize 5 methods splsda.select <- splsda.select[seq_len(5)]  splsda.upsetR <- UpSetR::fromList(splsda.select)  p <-  UpSetR::upset(splsda.upsetR, main.bar.color = 'gray36',       sets.bar.color = PLSDAbatch::pb_color(c(25:22,20)), matrix.color = 'gray36',       order.by = 'freq', empty.intersections = 'on',       queries = list(list(query = intersects,                            params = list('Before correction'),                            color = PLSDAbatch::pb_color(20), active = TRUE),                      list(query = intersects,                            params = list('removeBatchEffect'),                            color = PLSDAbatch::pb_color(22), active = TRUE),                      list(query = intersects,                            params = list('ComBat'),                            color = PLSDAbatch::pb_color(23), active = TRUE),                      list(query = intersects,                            params = list('PLSDA-batch'),                            color = PLSDAbatch::pb_color(24), active = TRUE),                      list(query = intersects,                            params = list('sPLSDA-batch'),                            color = PLSDAbatch::pb_color(25), active = TRUE)))"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"display-up","dir":"Articles","previous_headings":"","what":"Display Up","title":"Data Processing Phase 2 Report","text":"","code":"p"},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Data Processing Phase 2 Report","text":"conclusion, report highlights importance comprehensive data processing batch correction techniques ensuring reliability interpretability metabolomic data. systematically addressing batch effects selecting informative features, can improve robustness f downstream analyses enhance understanding biological phenomena. marks end Data Processing Phase 2 Report.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/articles/dataProcessing_phase_2.html","id":"clean-up-environment","dir":"Articles","previous_headings":"","what":"Clean up environment","title":"Data Processing Phase 2 Report","text":"rm(list = ls())","code":""},{"path":"https://danymukesha.github.io/dataPreparation/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dany Mukesha. Author, maintainer.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Mukesha D (2024). dataPreparation: Data Processing Metabolomics Analysis. R package version 0.1.0, https://danymukesha.github.io/dataPreparation/, https://github.com/danymukesha/dataPreparation.","code":"@Manual{,   title = {dataPreparation: Data Processing for Metabolomics Analysis},   author = {Dany Mukesha},   year = {2024},   note = {R package version 0.1.0, https://danymukesha.github.io/dataPreparation/},   url = {https://github.com/danymukesha/dataPreparation}, }"},{"path":[]},{"path":"https://danymukesha.github.io/dataPreparation/index.html","id":"data-processing-phase-1-report","dir":"","previous_headings":"","what":"Data Processing Phase 1 Report","title":"Data Processing for Metabolomics Analysis","text":"report outlines data processing steps involved phase 1. covers various preprocessing tasks reformatting material names, adding missing phenotype data, selecting metadata, deduplication, imputation missing values, performing principal component analysis (PCA). e.g.: Figure 1: pca_plot","code":""},{"path":"https://danymukesha.github.io/dataPreparation/index.html","id":"data-processing-phase-2-report","dir":"","previous_headings":"","what":"Data Processing Phase 2 Report","title":"Data Processing for Metabolomics Analysis","text":"report focuses data processing steps involved phase 2. encompasses filtering data, transforming using Compositional Log-Ratio (CLR) transformation, assessing batch effects, applying batch correction methods removeBatchEffect, ComBat, PLSDA-batch, sPLSDA-batch, percentile normalization. e.g.: Figure 2: batch_effect  Figure 3: batch_correction","code":""},{"path":"https://danymukesha.github.io/dataPreparation/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 dataPreparation authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/add_missing_phenotypes.html","id":null,"dir":"Reference","previous_headings":"","what":"Add missing phenotypes to samples — add_missing_phenotypes","title":"Add missing phenotypes to samples — add_missing_phenotypes","text":"function adds missing phenotypes samples based information  metadata table.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/add_missing_phenotypes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add missing phenotypes to samples — add_missing_phenotypes","text":"","code":"add_missing_phenotypes(   mt,   all_samples_info,   skip_descr = FALSE,   skip_mat = FALSE )"},{"path":"https://danymukesha.github.io/dataPreparation/reference/add_missing_phenotypes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add missing phenotypes to samples — add_missing_phenotypes","text":"mt data frame containing samples. all_samples_info data frame containing information missing phenotypes. skip_descr Logical indicating whether skip adding Sample.Description (default FALSE). skip_mat Logical indicating whether skip adding Material (default FALSE).","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/add_missing_phenotypes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add missing phenotypes to samples — add_missing_phenotypes","text":"data frame missing phenotypes added.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/corrected_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch cerration list for Package Examples — corrected_list","title":"Batch cerration list for Package Examples — corrected_list","text":"list contains two datasets used demonstrating examples  package.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/corrected_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch cerration list for Package Examples — corrected_list","text":"","code":"corrected_list"},{"path":"https://danymukesha.github.io/dataPreparation/reference/corrected_list.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Batch cerration list for Package Examples — corrected_list","text":"list 2 datasets: correction dataset containing raw data     batch correction removeBatchEffect dataset correcting raw data using     removeBatchEffect function `limma` R package.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/dataPreparation-package.html","id":null,"dir":"Reference","previous_headings":"","what":"dataPreparation: Data Processing for Metabolomics Analysis — dataPreparation-package","title":"dataPreparation: Data Processing for Metabolomics Analysis — dataPreparation-package","text":"Data Processing Metabolomics Analysis. package conatains two phases data processing. first evaluate dataset, second one adjust abnormality dataset.","code":""},{"path":[]},{"path":"https://danymukesha.github.io/dataPreparation/reference/dataPreparation-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"dataPreparation: Data Processing for Metabolomics Analysis — dataPreparation-package","text":"Maintainer: Dany Mukesha danymukesha@gmail.com (ORCID)","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/fncols.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill Missing Columns with NA Values — fncols","title":"Fill Missing Columns with NA Values — fncols","text":"function fills missing columns data frame NA values  based specified column names.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/fncols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill Missing Columns with NA Values — fncols","text":"","code":"fncols(data, cname)"},{"path":"https://danymukesha.github.io/dataPreparation/reference/fncols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill Missing Columns with NA Values — fncols","text":"data data frame. cname character vector specifying column names filled NA values.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/fncols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill Missing Columns with NA Values — fncols","text":"data frame missing columns filled NA values.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/imputed_data.html","id":null,"dir":"Reference","previous_headings":"","what":"The data frame with missing values imputed — imputed_data","title":"The data frame with missing values imputed — imputed_data","text":"dataset contains impute data missing values using k-nearest neighbors algorithm.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/imputed_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The data frame with missing values imputed — imputed_data","text":"","code":"imputed_data"},{"path":"https://danymukesha.github.io/dataPreparation/reference/imputed_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The data frame with missing values imputed — imputed_data","text":"data frame `m` observations(rows)  `n` variables(columns): ... numeric variables (Arg, Asn, Asp, Cit, Gln, Glu, Gly,          , Ile, Lys, Met, Orn, Phe, Pro, Ser, Thr, Trp, Tyr, Val, xLeu,          Ac.Orn, ADMA, alpha.AAA, c4.OH.Pro, Carnosine, Creatinine, DOPA,          Dopamine, Histamine, Kynurenine, Met., Nitro.Tyr, PEA, Putrescine,          Sarcosine, SDMA, Serotonin, Spermidine, Spermine, t4.OH.Pro,          Taurine, CE, DG, TG, LPC, PC, Cer, SM, H1).","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/impute_missing_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute missing values using k-nearest neighbors algorithm — impute_missing_values","title":"Impute missing values using k-nearest neighbors algorithm — impute_missing_values","text":"function imputes missing values dataset using k-nearest neighbors algorithm.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/impute_missing_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute missing values using k-nearest neighbors algorithm — impute_missing_values","text":"","code":"impute_missing_values(data, k = 5)"},{"path":"https://danymukesha.github.io/dataPreparation/reference/impute_missing_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute missing values using k-nearest neighbors algorithm — impute_missing_values","text":"data input data frame. k number nearest neighbors consider (default 5).","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/impute_missing_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute missing values using k-nearest neighbors algorithm — impute_missing_values","text":"data frame missing values imputed.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/perform_pca.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Principal Component Analysis (PCA) — perform_pca","title":"Perform Principal Component Analysis (PCA) — perform_pca","text":"function performs Principal Component Analysis (PCA)  input data.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/perform_pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Principal Component Analysis (PCA) — perform_pca","text":"","code":"perform_pca(data, scale_data = TRUE, center_data = TRUE)"},{"path":"https://danymukesha.github.io/dataPreparation/reference/perform_pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Principal Component Analysis (PCA) — perform_pca","text":"data input data frame. scale_data Logical indicating whether scale data (default TRUE). center_data Logical indicating whether center data (default TRUE).","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/perform_pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Principal Component Analysis (PCA) — perform_pca","text":"list containing PCA results, including principal component scores attributes.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/remove_high_missingness.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove columns and rows with high missingness — remove_high_missingness","title":"Remove columns and rows with high missingness — remove_high_missingness","text":"function removes columns rows high missing values dataset.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/remove_high_missingness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove columns and rows with high missingness — remove_high_missingness","text":"","code":"remove_high_missingness(data, col_threshold = 10, row_threshold = 10)"},{"path":"https://danymukesha.github.io/dataPreparation/reference/remove_high_missingness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove columns and rows with high missingness — remove_high_missingness","text":"data input data frame. col_threshold threshold percentage column-wise missing values (default 10`%`). row_threshold threshold percentage row-wise missing values (default 10`%`).","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/remove_high_missingness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove columns and rows with high missingness — remove_high_missingness","text":"list containing original data, cleaned data, details removed columns rows.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/sample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Data for Package Examples — sample_data","title":"Sample Data for Package Examples — sample_data","text":"dataset contains sample data used demonstrating examples package.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/sample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Data for Package Examples — sample_data","text":"","code":"sample_data"},{"path":"https://danymukesha.github.io/dataPreparation/reference/sample_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample Data for Package Examples — sample_data","text":"data frame 100 observations 68 variables: Sample.Type factor indicating type sample (Type1, Type2, Type3). Sample.Identification character vector specifying sample identification (ID1, ID2, ...). Gender factor indicating gender (Female, Male). Age integer indicating age. Sample.Description factor specifying sample description (DLB, msAD, miAD, HC). Submission.Name factor specifying submission name (plate1, plate2). Material factor indicating material (serum, sample). Apoe.Genotype factor indicating Apoe genotype (Apoe1, Apoe2, Apoe3, Apoe4). AC Numeric values AC. Ala Numeric values Ala. Arg Numeric values Arg. Asn Numeric values Asn. Asp Numeric values Asp. Cit Numeric values Cit. Gln Numeric values Gln. Glu Numeric values Glu. Gly Numeric values Gly. Numeric values . Ile Numeric values Ile. Lys Numeric values Lys. Met Numeric values Met. Orn Numeric values Orn. Phe Numeric values Phe. Pro Numeric values Pro. Ser Numeric values Ser. Thr Numeric values Thr. Trp Numeric values Trp. Tyr Numeric values Tyr. Val Numeric values Val. xLeu Numeric values xLeu. Ac.Orn Numeric values Ac.Orn. ADMA Numeric values ADMA. alpha.AAA Numeric values alpha.AAA. c4.OH.Pro Numeric values c4.OH.Pro. Carnosine Numeric values Carnosine. Creatinine Numeric values Creatinine. DOPA Numeric values DOPA. Dopamine Numeric values Dopamine. Histamine Numeric values Histamine. Kynurenine Numeric values Kynurenine. Met.Numeric values Met.. Nitro.Tyr Numeric values Nitro.Tyr. PEA Numeric values PEA. Putrescine Numeric values Putrescine. Sarcosine Numeric values Sarcosine. SDMA Numeric values SDMA. Serotonin Numeric values Serotonin. Spermidine Numeric values Spermidine. Spermine Numeric values Spermine. t4.OH.Pro Numeric values t4.OH.Pro. Taurine Numeric values Taurine. CE Numeric values CE. DG Numeric values DG. TG Numeric values TG. LPC Numeric values LPC. PC Numeric values PC. Cer Numeric values Cer. SM Numeric values SM. H1 Numeric values H1.","code":""},{"path":[]},{"path":"https://danymukesha.github.io/dataPreparation/reference/visualize_batch_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize Batch Correction Effects — visualize_batch_correction","title":"Visualize Batch Correction Effects — visualize_batch_correction","text":"function visualizes effects batch correction methods generating boxplot barplot.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/visualize_batch_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize Batch Correction Effects — visualize_batch_correction","text":"","code":"visualize_batch_correction(   corrected_list,   categories,   visualization_type = \"boxplot\" )"},{"path":"https://danymukesha.github.io/dataPreparation/reference/visualize_batch_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize Batch Correction Effects — visualize_batch_correction","text":"corrected_list list containing corrected data matrices. categories Classification samples visualization_type character string specifying type visualization.                          can either \"boxplot\" \"barplot\".","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/visualize_batch_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize Batch Correction Effects — visualize_batch_correction","text":"ggplot object representing visualization.","code":""},{"path":"https://danymukesha.github.io/dataPreparation/reference/visualize_batch_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize Batch Correction Effects — visualize_batch_correction","text":"","code":"#load correct.list from dataPreparation corrected_list <- dataPreparation::corrected_list n <- nrow(corrected_list$`Before correction`) categories <- dataPreparation::imputed_data$categories[1:n,]  # Visualize batch correction effects using boxplot visualize_batch_correction(corrected_list, categories,         visualization_type = \"boxplot\")   # Visualize batch correction effects using barplot visualize_batch_correction(corrected_list, categories,         visualization_type = \"barplot\")"}]
